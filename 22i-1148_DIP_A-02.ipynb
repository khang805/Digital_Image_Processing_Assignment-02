{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Manual Implementation of Edge Detection Algorithms\n",
        "- Canny Edge Detector\n",
        "- Marr-Hildreth (LoG) Edge Detector\n",
        "With evaluation against ground truth edge maps\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def normalize_image(image):\n",
        "    \"\"\"Normalize image to [0, 1] range\"\"\"\n",
        "    return image.astype(np.float32) / 255.0\n",
        "\n",
        "def read_image_grayscale(image_path):\n",
        "    \"\"\"Read image and convert to grayscale\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not read image: {image_path}\")\n",
        "\n",
        "    # Convert to grayscale if needed\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return normalize_image(image)\n",
        "\n",
        "def read_ground_truth(gt_path):\n",
        "    \"\"\"Read ground truth from .mat file or image file\"\"\"\n",
        "    if str(gt_path).endswith('.mat'):\n",
        "        # Load MATLAB file\n",
        "        try:\n",
        "            mat_data = loadmat(str(gt_path))\n",
        "            # Common keys in ground truth .mat files\n",
        "            possible_keys = ['groundTruth', 'gt', 'edge', 'edges', 'Boundaries', 'boundaries']\n",
        "\n",
        "            # Try to find the ground truth data\n",
        "            gt_data = None\n",
        "            for key in mat_data.keys():\n",
        "                if not key.startswith('__'):  # Skip metadata keys\n",
        "                    gt_data = mat_data[key]\n",
        "                    break\n",
        "\n",
        "            if gt_data is None:\n",
        "                raise ValueError(\"Could not find ground truth data in .mat file\")\n",
        "\n",
        "            # Handle different data structures\n",
        "            if isinstance(gt_data, np.ndarray):\n",
        "                if gt_data.dtype == np.object_:\n",
        "                    # Nested structure, extract first element\n",
        "                    gt_data = gt_data[0, 0]\n",
        "                    # Try to find 'Boundaries' or 'Segmentation' field\n",
        "                    if hasattr(gt_data, 'dtype') and gt_data.dtype.names:\n",
        "                        for field in gt_data.dtype.names:\n",
        "                            if 'bound' in field.lower() or 'seg' in field.lower():\n",
        "                                gt_data = gt_data[field][0, 0]\n",
        "                                break\n",
        "\n",
        "                # Ensure it's a 2D array\n",
        "                while len(gt_data.shape) > 2:\n",
        "                    gt_data = gt_data[0]\n",
        "\n",
        "                gt_image = gt_data.astype(np.float32)\n",
        "\n",
        "                # Normalize to [0, 1]\n",
        "                if gt_image.max() > 1:\n",
        "                    gt_image = gt_image / gt_image.max()\n",
        "\n",
        "                return gt_image\n",
        "            else:\n",
        "                raise ValueError(\"Unexpected ground truth data format\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error reading .mat file {gt_path}: {str(e)}\")\n",
        "    else:\n",
        "        # Regular image file\n",
        "        return read_image_grayscale(str(gt_path))\n",
        "\n",
        "# ============================================================================\n",
        "# GAUSSIAN SMOOTHING\n",
        "# ============================================================================\n",
        "\n",
        "def create_gaussian_kernel(size=5, sigma=1.0):\n",
        "    \"\"\"Create a Gaussian kernel manually\"\"\"\n",
        "    kernel = np.zeros((size, size))\n",
        "    center = size // 2\n",
        "\n",
        "    # Generate Gaussian kernel\n",
        "    sum_val = 0\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            x, y = i - center, j - center\n",
        "            kernel[i, j] = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
        "            sum_val += kernel[i, j]\n",
        "\n",
        "    # Normalize\n",
        "    kernel /= sum_val\n",
        "    return kernel\n",
        "\n",
        "def convolve2d(image, kernel):\n",
        "    \"\"\"Manual 2D convolution implementation\"\"\"\n",
        "    img_height, img_width = image.shape\n",
        "    kernel_height, kernel_width = kernel.shape\n",
        "\n",
        "    pad_h = kernel_height // 2\n",
        "    pad_w = kernel_width // 2\n",
        "\n",
        "    # Pad image\n",
        "    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='reflect')\n",
        "\n",
        "    # Output image\n",
        "    output = np.zeros_like(image)\n",
        "\n",
        "    # Perform convolution\n",
        "    for i in range(img_height):\n",
        "        for j in range(img_width):\n",
        "            region = padded[i:i+kernel_height, j:j+kernel_width]\n",
        "            output[i, j] = np.sum(region * kernel)\n",
        "\n",
        "    return output\n",
        "\n",
        "def gaussian_blur(image, kernel_size=5, sigma=1.0):\n",
        "    \"\"\"Apply Gaussian blur to image\"\"\"\n",
        "    kernel = create_gaussian_kernel(kernel_size, sigma)\n",
        "    return convolve2d(image, kernel)\n",
        "\n",
        "# ============================================================================\n",
        "# GRADIENT COMPUTATION\n",
        "# ============================================================================\n",
        "\n",
        "def compute_gradients(image):\n",
        "    \"\"\"Compute gradient magnitude and direction using Sobel operators\"\"\"\n",
        "    # Sobel kernels\n",
        "    sobel_x = np.array([[-1, 0, 1],\n",
        "                        [-2, 0, 2],\n",
        "                        [-1, 0, 1]], dtype=np.float32)\n",
        "\n",
        "    sobel_y = np.array([[-1, -2, -1],\n",
        "                        [ 0,  0,  0],\n",
        "                        [ 1,  2,  1]], dtype=np.float32)\n",
        "\n",
        "    # Compute gradients\n",
        "    grad_x = convolve2d(image, sobel_x)\n",
        "    grad_y = convolve2d(image, sobel_y)\n",
        "\n",
        "    # Compute magnitude and direction\n",
        "    magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "    direction = np.arctan2(grad_y, grad_x)\n",
        "\n",
        "    return magnitude, direction\n",
        "\n",
        "# ============================================================================\n",
        "# NON-MAXIMUM SUPPRESSION\n",
        "# ============================================================================\n",
        "\n",
        "def non_maximum_suppression(magnitude, direction):\n",
        "    \"\"\"Apply non-maximum suppression to gradient magnitude\"\"\"\n",
        "    height, width = magnitude.shape\n",
        "    suppressed = np.zeros_like(magnitude)\n",
        "\n",
        "    # Convert angle to degrees and normalize to [0, 180]\n",
        "    angle = np.rad2deg(direction) % 180\n",
        "\n",
        "    for i in range(1, height - 1):\n",
        "        for j in range(1, width - 1):\n",
        "            # Get angle sector (0, 45, 90, 135)\n",
        "            q = 255\n",
        "            r = 255\n",
        "\n",
        "            # 0 degrees\n",
        "            if (0 <= angle[i, j] < 22.5) or (157.5 <= angle[i, j] <= 180):\n",
        "                q = magnitude[i, j+1]\n",
        "                r = magnitude[i, j-1]\n",
        "            # 45 degrees\n",
        "            elif 22.5 <= angle[i, j] < 67.5:\n",
        "                q = magnitude[i+1, j-1]\n",
        "                r = magnitude[i-1, j+1]\n",
        "            # 90 degrees\n",
        "            elif 67.5 <= angle[i, j] < 112.5:\n",
        "                q = magnitude[i+1, j]\n",
        "                r = magnitude[i-1, j]\n",
        "            # 135 degrees\n",
        "            elif 112.5 <= angle[i, j] < 157.5:\n",
        "                q = magnitude[i-1, j-1]\n",
        "                r = magnitude[i+1, j+1]\n",
        "\n",
        "            # Suppress non-maximum\n",
        "            if magnitude[i, j] >= q and magnitude[i, j] >= r:\n",
        "                suppressed[i, j] = magnitude[i, j]\n",
        "\n",
        "    return suppressed\n",
        "\n",
        "# ============================================================================\n",
        "# DOUBLE THRESHOLDING AND EDGE TRACKING\n",
        "# ============================================================================\n",
        "\n",
        "def double_threshold(image, low_ratio=0.05, high_ratio=0.15):\n",
        "    \"\"\"Apply double thresholding\"\"\"\n",
        "    high_threshold = image.max() * high_ratio\n",
        "    low_threshold = high_threshold * low_ratio\n",
        "\n",
        "    strong = 1.0\n",
        "    weak = 0.5\n",
        "\n",
        "    result = np.zeros_like(image)\n",
        "\n",
        "    strong_i, strong_j = np.where(image >= high_threshold)\n",
        "    weak_i, weak_j = np.where((image <= high_threshold) & (image >= low_threshold))\n",
        "\n",
        "    result[strong_i, strong_j] = strong\n",
        "    result[weak_i, weak_j] = weak\n",
        "\n",
        "    return result, weak, strong\n",
        "\n",
        "def edge_tracking_by_hysteresis(image, weak=0.5, strong=1.0):\n",
        "    \"\"\"Track edges by hysteresis\"\"\"\n",
        "    height, width = image.shape\n",
        "\n",
        "    for i in range(1, height - 1):\n",
        "        for j in range(1, width - 1):\n",
        "            if image[i, j] == weak:\n",
        "                # Check 8-connected neighbors\n",
        "                if ((image[i+1, j-1] == strong) or (image[i+1, j] == strong) or\n",
        "                    (image[i+1, j+1] == strong) or (image[i, j-1] == strong) or\n",
        "                    (image[i, j+1] == strong) or (image[i-1, j-1] == strong) or\n",
        "                    (image[i-1, j] == strong) or (image[i-1, j+1] == strong)):\n",
        "                    image[i, j] = strong\n",
        "                else:\n",
        "                    image[i, j] = 0\n",
        "\n",
        "    return image\n",
        "\n",
        "# ============================================================================\n",
        "# CANNY EDGE DETECTOR\n",
        "# ============================================================================\n",
        "\n",
        "def canny_edge_detector(image, sigma=1.0, low_threshold=0.05, high_threshold=0.15):\n",
        "    \"\"\"\n",
        "    Manual implementation of Canny edge detector\n",
        "\n",
        "    Steps:\n",
        "    1. Gaussian smoothing\n",
        "    2. Gradient computation\n",
        "    3. Non-maximum suppression\n",
        "    4. Double thresholding\n",
        "    5. Edge tracking by hysteresis\n",
        "    \"\"\"\n",
        "    # Step 1: Gaussian smoothing\n",
        "    smoothed = gaussian_blur(image, kernel_size=5, sigma=sigma)\n",
        "\n",
        "    # Step 2: Compute gradients\n",
        "    magnitude, direction = compute_gradients(smoothed)\n",
        "\n",
        "    # Step 3: Non-maximum suppression\n",
        "    suppressed = non_maximum_suppression(magnitude, direction)\n",
        "\n",
        "    # Step 4: Double thresholding\n",
        "    thresholded, weak, strong = double_threshold(suppressed, low_threshold, high_threshold)\n",
        "\n",
        "    # Step 5: Edge tracking by hysteresis\n",
        "    edges = edge_tracking_by_hysteresis(thresholded, weak, strong)\n",
        "\n",
        "    # Convert to binary (0 or 1)\n",
        "    edges = (edges == strong).astype(np.float32)\n",
        "\n",
        "    return edges\n",
        "\n",
        "# ============================================================================\n",
        "# LAPLACIAN OF GAUSSIAN (LoG)\n",
        "# ============================================================================\n",
        "\n",
        "def create_log_kernel(size=9, sigma=1.0):\n",
        "    \"\"\"Create Laplacian of Gaussian (LoG) kernel\"\"\"\n",
        "    kernel = np.zeros((size, size))\n",
        "    center = size // 2\n",
        "\n",
        "    # Generate LoG kernel\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            x = i - center\n",
        "            y = j - center\n",
        "\n",
        "            # LoG formula: -1/(πσ^4) * [1 - (x^2+y^2)/(2σ^2)] * exp(-(x^2+y^2)/(2σ^2))\n",
        "            r_squared = x**2 + y**2\n",
        "            sigma_squared = sigma**2\n",
        "\n",
        "            gaussian = np.exp(-r_squared / (2 * sigma_squared))\n",
        "            kernel[i, j] = -(1 / (np.pi * sigma_squared**2)) * \\\n",
        "                          (1 - r_squared / (2 * sigma_squared)) * gaussian\n",
        "\n",
        "    # Normalize to sum to zero\n",
        "    kernel = kernel - np.mean(kernel)\n",
        "\n",
        "    return kernel\n",
        "\n",
        "def zero_crossing(image):\n",
        "    \"\"\"Detect zero crossings in LoG filtered image\"\"\"\n",
        "    height, width = image.shape\n",
        "    zero_crossings = np.zeros_like(image)\n",
        "\n",
        "    for i in range(1, height - 1):\n",
        "        for j in range(1, width - 1):\n",
        "            # Check for zero crossing by looking at sign changes\n",
        "            neighbors = [\n",
        "                image[i-1, j], image[i+1, j],\n",
        "                image[i, j-1], image[i, j+1],\n",
        "                image[i-1, j-1], image[i+1, j+1],\n",
        "                image[i-1, j+1], image[i+1, j-1]\n",
        "            ]\n",
        "\n",
        "            # If center pixel is positive and has negative neighbor (or vice versa)\n",
        "            if image[i, j] > 0:\n",
        "                if any(n < 0 for n in neighbors):\n",
        "                    zero_crossings[i, j] = 1\n",
        "            elif image[i, j] < 0:\n",
        "                if any(n > 0 for n in neighbors):\n",
        "                    zero_crossings[i, j] = 1\n",
        "\n",
        "    return zero_crossings\n",
        "\n",
        "def marr_hildreth_edge_detector(image, sigma=1.0, threshold=0.01):\n",
        "    \"\"\"\n",
        "    Manual implementation of Marr-Hildreth (LoG) edge detector\n",
        "\n",
        "    Steps:\n",
        "    1. Apply LoG filter\n",
        "    2. Find zero crossings\n",
        "    3. Threshold based on gradient magnitude\n",
        "    \"\"\"\n",
        "    # Step 1: Apply LoG filter\n",
        "    kernel_size = int(6 * sigma + 1)\n",
        "    if kernel_size % 2 == 0:\n",
        "        kernel_size += 1\n",
        "\n",
        "    log_kernel = create_log_kernel(kernel_size, sigma)\n",
        "    log_filtered = convolve2d(image, log_kernel)\n",
        "\n",
        "    # Step 2: Find zero crossings\n",
        "    edges = zero_crossing(log_filtered)\n",
        "\n",
        "    # Step 3: Threshold based on gradient magnitude\n",
        "    magnitude, _ = compute_gradients(image)\n",
        "    threshold_value = np.max(magnitude) * threshold\n",
        "    edges = edges * (magnitude > threshold_value)\n",
        "\n",
        "    return edges.astype(np.float32)\n",
        "\n",
        "# ============================================================================\n",
        "# EVALUATION METRICS\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_metrics(detected_edges, ground_truth):\n",
        "    \"\"\"Calculate Precision, Recall, and F1 Score\"\"\"\n",
        "    # Flatten arrays\n",
        "    detected = detected_edges.flatten() > 0.5\n",
        "    gt = ground_truth.flatten() > 0.5\n",
        "\n",
        "    # Calculate True Positives, False Positives, False Negatives\n",
        "    TP = np.sum(detected & gt)\n",
        "    FP = np.sum(detected & ~gt)\n",
        "    FN = np.sum(~detected & gt)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score,\n",
        "        'TP': TP,\n",
        "        'FP': FP,\n",
        "        'FN': FN\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_results(original, canny_edges, log_edges, ground_truth,\n",
        "                     canny_metrics, log_metrics, save_path=None):\n",
        "    \"\"\"Visualize edge detection results\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "\n",
        "    # Original image\n",
        "    axes[0, 0].imshow(original, cmap='gray')\n",
        "    axes[0, 0].set_title('Original Image')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # Canny edges\n",
        "    axes[0, 1].imshow(canny_edges, cmap='gray')\n",
        "    axes[0, 1].set_title(f'Canny Edge Detection\\n' +\n",
        "                         f'P={canny_metrics[\"precision\"]:.3f}, ' +\n",
        "                         f'R={canny_metrics[\"recall\"]:.3f}, ' +\n",
        "                         f'F1={canny_metrics[\"f1_score\"]:.3f}')\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    # Marr-Hildreth edges\n",
        "    axes[1, 0].imshow(log_edges, cmap='gray')\n",
        "    axes[1, 0].set_title(f'Marr-Hildreth (LoG) Edge Detection\\n' +\n",
        "                         f'P={log_metrics[\"precision\"]:.3f}, ' +\n",
        "                         f'R={log_metrics[\"recall\"]:.3f}, ' +\n",
        "                         f'F1={log_metrics[\"f1_score\"]:.3f}')\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    # Ground truth\n",
        "    axes[1, 1].imshow(ground_truth, cmap='gray')\n",
        "    axes[1, 1].set_title('Ground Truth')\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN PROCESSING FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def process_dataset(images_folder, ground_truth_folder, output_folder):\n",
        "    \"\"\"Process all images in the dataset\"\"\"\n",
        "\n",
        "    # Create output directories\n",
        "    output_folder = Path(output_folder)\n",
        "    output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    canny_output = output_folder / 'canny_edges'\n",
        "    log_output = output_folder / 'marr_hildreth_edges'\n",
        "    comparison_output = output_folder / 'comparisons'\n",
        "\n",
        "    canny_output.mkdir(exist_ok=True)\n",
        "    log_output.mkdir(exist_ok=True)\n",
        "    comparison_output.mkdir(exist_ok=True)\n",
        "\n",
        "    # Get list of images\n",
        "    images_folder = Path(images_folder)\n",
        "    ground_truth_folder = Path(ground_truth_folder)\n",
        "\n",
        "    image_files = sorted(list(images_folder.glob('*.jpg')) +\n",
        "                        list(images_folder.glob('*.png')) +\n",
        "                        list(images_folder.glob('*.bmp')))\n",
        "\n",
        "    if len(image_files) == 0:\n",
        "        print(f\"No images found in {images_folder}\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Found {len(image_files)} images to process\")\n",
        "\n",
        "    # Get list of ground truth files for matching\n",
        "    gt_files = {}\n",
        "    for gt_path in ground_truth_folder.glob('*'):\n",
        "        if gt_path.is_file():\n",
        "            # Store with stem (filename without extension) as key\n",
        "            gt_files[gt_path.stem] = gt_path\n",
        "\n",
        "    print(f\"Found {len(gt_files)} ground truth files\")\n",
        "\n",
        "    # Store results\n",
        "    results = []\n",
        "    skipped = 0\n",
        "\n",
        "    # Process each image\n",
        "    for img_path in tqdm(image_files, desc=\"Processing images\"):\n",
        "        try:\n",
        "            # Read image\n",
        "            image = read_image_grayscale(str(img_path))\n",
        "\n",
        "            # Try to find matching ground truth\n",
        "            # Remove 'img' suffix if present and try different variations\n",
        "            img_stem = img_path.stem\n",
        "\n",
        "            # Try exact match first\n",
        "            gt_path = None\n",
        "            if img_stem in gt_files:\n",
        "                gt_path = gt_files[img_stem]\n",
        "            # Try without 'img' suffix\n",
        "            elif img_stem.endswith('img'):\n",
        "                stem_without_img = img_stem[:-3]\n",
        "                if stem_without_img in gt_files:\n",
        "                    gt_path = gt_files[stem_without_img]\n",
        "            # Try adding 'img' suffix\n",
        "            else:\n",
        "                stem_with_img = img_stem + 'img'\n",
        "                if stem_with_img in gt_files:\n",
        "                    gt_path = gt_files[stem_with_img]\n",
        "\n",
        "            if gt_path is None:\n",
        "                skipped += 1\n",
        "                if skipped <= 10:  # Only print first 10 to avoid clutter\n",
        "                    print(f\"No matching ground truth for {img_path.name}\")\n",
        "                continue\n",
        "\n",
        "            ground_truth = read_ground_truth(gt_path)\n",
        "\n",
        "            # Apply Canny edge detection\n",
        "            canny_edges = canny_edge_detector(image, sigma=1.4,\n",
        "                                             low_threshold=0.05,\n",
        "                                             high_threshold=0.15)\n",
        "\n",
        "            # Apply Marr-Hildreth edge detection\n",
        "            log_edges = marr_hildreth_edge_detector(image, sigma=2.0,\n",
        "                                                    threshold=0.01)\n",
        "\n",
        "            # Calculate metrics\n",
        "            canny_metrics = calculate_metrics(canny_edges, ground_truth)\n",
        "            log_metrics = calculate_metrics(log_edges, ground_truth)\n",
        "\n",
        "            # Save edge maps\n",
        "            cv2.imwrite(str(canny_output / img_path.name),\n",
        "                       (canny_edges * 255).astype(np.uint8))\n",
        "            cv2.imwrite(str(log_output / img_path.name),\n",
        "                       (log_edges * 255).astype(np.uint8))\n",
        "\n",
        "            # Visualize and save comparison\n",
        "            visualize_results(image, canny_edges, log_edges, ground_truth,\n",
        "                            canny_metrics, log_metrics,\n",
        "                            save_path=comparison_output / f\"comparison_{img_path.stem}.png\")\n",
        "\n",
        "            # Store results\n",
        "            results.append({\n",
        "                'image': img_path.name,\n",
        "                'ground_truth': gt_path.name,\n",
        "                'canny_precision': canny_metrics['precision'],\n",
        "                'canny_recall': canny_metrics['recall'],\n",
        "                'canny_f1': canny_metrics['f1_score'],\n",
        "                'log_precision': log_metrics['precision'],\n",
        "                'log_recall': log_metrics['recall'],\n",
        "                'log_f1': log_metrics['f1_score']\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path.name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    if skipped > 10:\n",
        "        print(f\"Skipped {skipped} images total (no matching ground truth)\")\n",
        "\n",
        "    # Check if we have any results\n",
        "    if len(results) == 0:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ERROR: No images were successfully processed!\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\nPossible issues:\")\n",
        "        print(\"1. Ground truth filenames don't match image filenames\")\n",
        "        print(\"2. Check the naming pattern in both folders\")\n",
        "        print(\"\\nExample image files found:\")\n",
        "        for img in list(image_files)[:5]:\n",
        "            print(f\"  - {img.name}\")\n",
        "        print(\"\\nExample ground truth files found:\")\n",
        "        for gt_name in list(gt_files.keys())[:5]:\n",
        "            print(f\"  - {gt_name}\")\n",
        "        return None, None\n",
        "\n",
        "    # Create results dataframe\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_metrics = {\n",
        "        'Canny Precision': df['canny_precision'].mean(),\n",
        "        'Canny Recall': df['canny_recall'].mean(),\n",
        "        'Canny F1': df['canny_f1'].mean(),\n",
        "        'LoG Precision': df['log_precision'].mean(),\n",
        "        'LoG Recall': df['log_recall'].mean(),\n",
        "        'LoG F1': df['log_f1'].mean()\n",
        "    }\n",
        "\n",
        "    # Save results\n",
        "    df.to_csv(output_folder / 'detailed_results.csv', index=False)\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EDGE DETECTION RESULTS SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nProcessed {len(df)} images successfully\")\n",
        "    print(f\"Skipped {skipped} images (no matching ground truth)\\n\")\n",
        "    print(\"Average Metrics:\")\n",
        "    print(\"-\" * 60)\n",
        "    for metric, value in avg_metrics.items():\n",
        "        print(f\"{metric:20s}: {value:.4f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Create summary visualization\n",
        "    create_summary_plot(df, output_folder)\n",
        "\n",
        "    return df, avg_metrics\n",
        "\n",
        "def create_summary_plot(df, output_folder):\n",
        "    \"\"\"Create summary comparison plot\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    metrics = ['precision', 'recall', 'f1']\n",
        "    titles = ['Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "    for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
        "        canny_values = df[f'canny_{metric}'].values\n",
        "        log_values = df[f'log_{metric}'].values\n",
        "\n",
        "        x = np.arange(len(canny_values))\n",
        "        width = 0.35\n",
        "\n",
        "        axes[idx].bar(x - width/2, canny_values, width, label='Canny', alpha=0.8)\n",
        "        axes[idx].bar(x + width/2, log_values, width, label='Marr-Hildreth', alpha=0.8)\n",
        "\n",
        "        axes[idx].set_xlabel('Image Index')\n",
        "        axes[idx].set_ylabel(title)\n",
        "        axes[idx].set_title(f'{title} Comparison')\n",
        "        axes[idx].legend()\n",
        "        axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_folder / 'metrics_comparison.png', dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    # Mount Google Drive if not already mounted\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        if not os.path.exists('/content/drive'):\n",
        "            drive.mount('/content/drive')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Define paths - UPDATE THESE TO MATCH YOUR ACTUAL FOLDER STRUCTURE\n",
        "    # Try different possible paths\n",
        "    possible_base_paths = [\n",
        "        \"/content/drive/MyDrive/DIP_A-02_Images/Images\",\n",
        "        \"/content/drive/MyDrive/DIP_A-02_Images\",\n",
        "        \"/content/DIP_A-02_Images/Images\",\n",
        "        \"/content/DIP_A-02_Images\"\n",
        "    ]\n",
        "\n",
        "    base_path = None\n",
        "    for path in possible_base_paths:\n",
        "        if os.path.exists(path):\n",
        "            base_path = path\n",
        "            break\n",
        "\n",
        "    if base_path is None:\n",
        "        print(\"Error: Could not find the dataset folder. Please check the path.\")\n",
        "        print(\"Tried the following paths:\")\n",
        "        for path in possible_base_paths:\n",
        "            print(f\"  - {path}\")\n",
        "        print(\"\\nPlease update the paths in the main() function to match your folder structure.\")\n",
        "        return\n",
        "\n",
        "    images_folder = os.path.join(base_path, \"images\")\n",
        "    ground_truth_folder = os.path.join(base_path, \"ground_truth\")\n",
        "    output_folder = os.path.join(os.path.dirname(base_path), \"output\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"MANUAL EDGE DETECTION IMPLEMENTATION\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nBase path: {base_path}\")\n",
        "    print(f\"Images folder: {images_folder}\")\n",
        "    print(f\"Ground truth folder: {ground_truth_folder}\")\n",
        "    print(f\"Output folder: {output_folder}\\n\")\n",
        "\n",
        "    # Check if folders exist\n",
        "    if not os.path.exists(images_folder):\n",
        "        print(f\"Error: Images folder not found at {images_folder}\")\n",
        "        print(f\"\\nChecking what exists in {base_path}:\")\n",
        "        if os.path.exists(base_path):\n",
        "            contents = os.listdir(base_path)\n",
        "            print(f\"Contents: {contents}\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(ground_truth_folder):\n",
        "        print(f\"Error: Ground truth folder not found at {ground_truth_folder}\")\n",
        "        print(f\"\\nChecking what exists in {base_path}:\")\n",
        "        if os.path.exists(base_path):\n",
        "            contents = os.listdir(base_path)\n",
        "            print(f\"Contents: {contents}\")\n",
        "        return\n",
        "\n",
        "    # Process dataset\n",
        "    result = process_dataset(images_folder, ground_truth_folder, output_folder)\n",
        "\n",
        "    if result is None or result[0] is None:\n",
        "        print(\"\\nProcessing failed. Please check the error messages above.\")\n",
        "        return\n",
        "\n",
        "    df, avg_metrics = result\n",
        "\n",
        "    print(f\"\\nResults saved to: {output_folder}\")\n",
        "    print(\"Output folders created:\")\n",
        "    print(f\"  - Canny edges: {output_folder}/canny_edges\")\n",
        "    print(f\"  - Marr-Hildreth edges: {output_folder}/marr_hildreth_edges\")\n",
        "    print(f\"  - Comparisons: {output_folder}/comparisons\")\n",
        "    print(f\"  - Detailed results CSV: {output_folder}/detailed_results.csv\")\n",
        "    print(f\"  - Summary plot: {output_folder}/metrics_comparison.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c89nlMLMjcH8",
        "outputId": "44a25caa-342d-4883-b129-15ee8e687016"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "============================================================\n",
            "MANUAL EDGE DETECTION IMPLEMENTATION\n",
            "============================================================\n",
            "\n",
            "Base path: /content/drive/MyDrive/DIP_A-02_Images/Images\n",
            "Images folder: /content/drive/MyDrive/DIP_A-02_Images/Images/images\n",
            "Ground truth folder: /content/drive/MyDrive/DIP_A-02_Images/Images/ground_truth\n",
            "Output folder: /content/drive/MyDrive/DIP_A-02_Images/output\n",
            "\n",
            "Found 200 images to process\n",
            "Found 200 ground truth files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 200/200 [26:28<00:00,  7.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "EDGE DETECTION RESULTS SUMMARY\n",
            "============================================================\n",
            "\n",
            "Processed 200 images successfully\n",
            "Skipped 0 images (no matching ground truth)\n",
            "\n",
            "Average Metrics:\n",
            "------------------------------------------------------------\n",
            "Canny Precision     : 0.3163\n",
            "Canny Recall        : 0.1470\n",
            "Canny F1            : 0.1766\n",
            "LoG Precision       : 0.2982\n",
            "LoG Recall          : 0.6095\n",
            "LoG F1              : 0.3665\n",
            "============================================================\n",
            "\n",
            "Results saved to: /content/drive/MyDrive/DIP_A-02_Images/output\n",
            "Output folders created:\n",
            "  - Canny edges: /content/drive/MyDrive/DIP_A-02_Images/output/canny_edges\n",
            "  - Marr-Hildreth edges: /content/drive/MyDrive/DIP_A-02_Images/output/marr_hildreth_edges\n",
            "  - Comparisons: /content/drive/MyDrive/DIP_A-02_Images/output/comparisons\n",
            "  - Detailed results CSV: /content/drive/MyDrive/DIP_A-02_Images/output/detailed_results.csv\n",
            "  - Summary plot: /content/drive/MyDrive/DIP_A-02_Images/output/metrics_comparison.png\n"
          ]
        }
      ]
    }
  ]
}